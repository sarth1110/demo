{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXvPKV9KbNR5",
    "outputId": "c40369f7-1178-4e95-e110-3891e9947e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\kanan\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\kanan\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\kanan\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\kanan\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: statistics in c:\\users\\kanan\\anaconda3\\lib\\site-packages (1.0.3.5)\n",
      "Requirement already satisfied: docutils>=0.3 in c:\\users\\kanan\\anaconda3\\lib\\site-packages (from statistics) (0.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "! pip install statistics\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xbY0S0HwbNR2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from statistics import mean\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7fQo5Zvus-e",
    "outputId": "366375c6-3ec3-4fc5-93c2-6a5b44d1353c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining stop words to be removed from the review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'to', 'from', 'on', 'here', 'there', 'when', 'where', 'why', 'how', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKKt1yQFbNR5"
   },
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading data from https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz using read_csv function from pandas. Here this function will first uncompress the gzip file using gzip tool and then read the data from tsv file into pandas dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdJQy-ZybNR6",
    "outputId": "dc30933c-2fab-41a8-ed8f-93d17b561da5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanan\\AppData\\Local\\Temp\\ipykernel_21720\\338091884.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz', compression='gzip', sep='\\t', on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz', compression='gzip', sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KA4XYw7bNR6"
   },
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting just the star_rating and review_body columns from the entire dataFrame. \n",
    "##### Also dropped all the nan values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "a4Pq05VNbNR7"
   },
   "outputs": [],
   "source": [
    "data = data.loc[:, [\"star_rating\", \"review_body\"]]\n",
    "data = data.dropna()\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divided the dataset into 3 classes such that star_rating 1&2 belong to class 1, star_rating 3 belongs to class 2, and star_rating 4&5 belong to class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EfAuMrnb8Y5a"
   },
   "outputs": [],
   "source": [
    "def classifyRatingGroup(x):\n",
    "    if x==1 or x==2 or x=='1' or x=='2':\n",
    "        return 1\n",
    "    elif x==3 or x=='3':\n",
    "        return 2\n",
    "    elif x==4 or x==5 or x=='4' or x=='5':\n",
    "        return 3\n",
    "data['rating_group'] = data['star_rating'].apply(classifyRatingGroup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9PV9drobNR7"
   },
   "source": [
    " ## We form three classes and select 20000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouped the dataframe using the new rating_group class and extracted 20,000 random reviews from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xwarx8H0bNR7"
   },
   "outputs": [],
   "source": [
    "rgData = data.groupby('rating_group')\n",
    "\n",
    "temp=[]\n",
    "for group, data in rgData:\n",
    "    temp.append(data.sample(20000, random_state=0))\n",
    "    \n",
    "fData = pd.concat([temp[0], temp[1], temp[2]])\n",
    "fData = fData.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = mean([len(w) for w in list(fData[\"review_body\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5FVlcg5bNR8"
   },
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0IFj2GGbNR8"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ExpandContraction is used to remove contractions from the reviews (eg: won't => will not).\n",
    "##### CleanData will remove all the HTML tags, URL tokens, any special symbol other than alphabets and numbers, and numbers that occur alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hzwtpkbdbNR9"
   },
   "outputs": [],
   "source": [
    "def expandContraction(text):\n",
    "    expandedWords = []\n",
    "    for w in text.split():\n",
    "        expandedWords.append(contractions.fix(w))\n",
    "    return ' '.join(expandedWords)\n",
    "\n",
    "def cleanData(review):\n",
    "    review = re.sub(r'<.*>', ' ', review)            #Removes HTML tags\n",
    "    review = re.sub(r'http[s]?://\\S+', ' ', review)  #Removes URL tokens\n",
    "    review = re.sub(r'[^a-zA-Z0-9\\s]', ' ', review)  #Removes all characters other than alphabets and numbers\n",
    "    review = re.sub(r'\\s[0-9]*', ' ', review)        #Removes all numbers occuring independently\n",
    "    review = re.sub(r'^[0-9]*\\s', '', review)        #Removes all numbers at the start of a string\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Convert the reviews into lowercase\n",
    "##### 2) Expand Contractions\n",
    "##### 3) Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "itEgyhLnLFjk"
   },
   "outputs": [],
   "source": [
    "fData['review_body'] = fData['review_body'].apply(lambda x: x.lower())\n",
    "fData['review_body'] = fData['review_body'].apply(expandContraction)\n",
    "fData['review_body'] = fData['review_body'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of review before and after data cleaning: 270.2979833333333, 238.55773333333335\n"
     ]
    }
   ],
   "source": [
    "x2 = mean([len(word) for word in list(fData[\"review_body\"])])\n",
    "print(\"Average length of review before and after data cleaning: \"+str(x1)+\", \"+str(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QbZs2HFbNR-"
   },
   "source": [
    "## Perform Lemmatization  & Remove the Stop Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) removeStopWords will remove stop words that are present in nltk stop_words from the review\n",
    "##### 2) posTagger assigns part of speech to tokens in review\n",
    "##### 3) lemmatizeText performs lemmatization on the review based on POS tags assigned by posTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "euSuWs-jr41v"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def removeStopWords(text):\n",
    "    tmp=[]\n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            tmp.append(w)\n",
    "    return tmp\n",
    "\n",
    "def joinList(text):\n",
    "    return ' '.join(text)\n",
    "\n",
    "def posTagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    "\n",
    "def lemmatizeText(text):\n",
    "    posTagged = nltk.pos_tag(nltk.word_tokenize(text)) \n",
    "    wordnetTagged = list(map(lambda x: (x[0], posTagger(x[1])), posTagged))\n",
    "\n",
    "    lemmatizedSentence = []\n",
    "    for word, tag in wordnetTagged:\n",
    "        if tag is None:\n",
    "            lemmatizedSentence.append(word)\n",
    "        else:       \n",
    "            lemmatizedSentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    \n",
    "    return lemmatizedSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform lemmatization, remove stop words and join the pre-processed tokens into sentences to pass into tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fData['review_body'] = fData['review_body'].apply(lemmatizeText)\n",
    "fData['review_body'] = fData['review_body'].apply(removeStopWords)\n",
    "fData['review_body'] = fData['review_body'].apply(joinList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of review before and after data pre-processing: 238.55773333333335, 153.46318333333335\n"
     ]
    }
   ],
   "source": [
    "x3 = mean([len(word) for word in list(fData[\"review_body\"])])\n",
    "print(\"Average length of review before and after data pre-processing: \"+str(x2)+\", \"+str(x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up-FlRyHbNR-"
   },
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the dataset into train and test data. Stratify is used to create a balanced test data consisting of equal data of all the classes. I have splitted the 80% data into training set and 20% into testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "s93K1DnyFDlK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fData['review_body'], fData['rating_group'], stratify=fData['rating_group'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating TF-IDF vector from review_body using TfidfVectorizer. We have set the max features to be taken into account as 10,000 and ngram_range represents the lower and upper boundary of the range of ngrams to be extracted in the feature vector.\n",
    "##### Next I have converted the TF-IDF features of training data and test data into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ncPtYsRwbNR-"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1,3), max_features = 10000)\n",
    "tfidf.fit(fData['review_body'].values)\n",
    "trainFeatures = tfidf.transform(X_train)\n",
    "testFeatures = tfidf.transform(X_test)\n",
    "\n",
    "trainFeatures = pd.DataFrame(trainFeatures.toarray(), columns=tfidf.get_feature_names_out())\n",
    "testFeatures = pd.DataFrame(testFeatures.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printVal(f1, recall, precision):\n",
    "    print(\"For class 1 Precision, Recall, and F1 score is \"+str(precision[0])+\", \"+str(recall[0])+\", and \"+str(f1[0])+\" respectively.\")\n",
    "    print(\"For class 2 Precision, Recall, and F1 score is \"+str(precision[1])+\", \"+str(recall[1])+\", and \"+str(f1[1])+\" respectively.\")\n",
    "    print(\"For class 3 Precision, Recall, and F1 score is \"+str(precision[2])+\", \"+str(recall[2])+\", and \"+str(f1[2])+\" respectively.\")\n",
    "    print(\"Average Precision, Recall, and F1 score are \"+str(mean(f1))+\", \"+str(mean(recall))+\", and \"+str(mean(precision))+\" respectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEF7skH1bNR-"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created Perceptron model using scikit learn to train model based on tf-idf features of training set reviews and rating_group of the respective reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LQ6jIhCbNR-",
    "outputId": "e41586fb-2462-4d62-b043-3530ed681d38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perceptronModel = Perceptron()\n",
    "perceptronModel.fit(trainFeatures, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating F1 score, recall and precision for Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLOQ04IBtWC4",
    "outputId": "0c345bd5-368b-474d-9764-d2619a7d8b97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 1 Precision, Recall, and F1 score is 0.64175, 0.7286403633267102, and 0.6824405157516948 respectively.\n",
      "For class 2 Precision, Recall, and F1 score is 0.51825, 0.5963751438434983, and 0.5545746388443018 respectively.\n",
      "For class 3 Precision, Recall, and F1 score is 0.843, 0.6742651469706059, and 0.7492500833240752 respectively.\n",
      "Average Precision, Recall, and F1 score are 0.6620884126400239, 0.6664268847136048, and 0.6676666666666666 respectively\n"
     ]
    }
   ],
   "source": [
    "PPrediction = perceptronModel.predict(testFeatures)\n",
    "f1 = f1_score(PPrediction, y_test, average=None)\n",
    "recall = recall_score(PPrediction, y_test, average=None)\n",
    "precision = precision_score(PPrediction, y_test, average=None)\n",
    "printVal(f1, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "431vsvEJbNR_"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created Linear Support Vector Classifier model using scikit learn to train model based on tf-idf features of training set reviews and rating_group of the respective reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LSVC = LinearSVC(C=0.1)\n",
    "LSVC.fit(trainFeatures, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating F1 score, recall and precision for Linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 1 Precision, Recall, and F1 score is 0.74925, 0.7230398069963812, and 0.7359116022099447 respectively.\n",
      "For class 2 Precision, Recall, and F1 score is 0.5945, 0.6567246616956642, and 0.6240650833223987 respectively.\n",
      "For class 3 Precision, Recall, and F1 score is 0.8295, 0.783656117146906, and 0.8059266456157396 respectively.\n",
      "Average Precision, Recall, and F1 score are 0.721967777049361, 0.7211401952796505, and 0.7244166666666667 respectively\n"
     ]
    }
   ],
   "source": [
    "LSVCPrediction = LSVC.predict(testFeatures)\n",
    "f1 = f1_score(LSVCPrediction, y_test, average=None)\n",
    "recall = recall_score(LSVCPrediction, y_test, average=None)\n",
    "precision = precision_score(LSVCPrediction, y_test, average=None)\n",
    "printVal(f1, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmE_QPH3bNR_"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created Logistic Regression model using scikit learn to train model based on tf-idf features of training set reviews and rating_group of the respective reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jyxL5dXbNR_",
    "outputId": "2996453f-cfa6-4fc8-ae6e-143ea1e84d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, solver='saga')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegressionModel = LogisticRegression(max_iter=5000, solver = 'saga')\n",
    "logisticRegressionModel.fit(trainFeatures, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating F1 score, recall and precision for Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kH2-txj6bNR_",
    "outputId": "29c7586b-7c8d-44ed-9e7e-73e4f2ade65a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 1 Precision, Recall, and F1 score is 0.73625, 0.7344139650872819, and 0.735330836454432 respectively.\n",
      "For class 2 Precision, Recall, and F1 score is 0.62225, 0.6401748971193416, and 0.6310851926977687 respectively.\n",
      "For class 3 Precision, Recall, and F1 score is 0.8185, 0.7981472452462214, and 0.8081955072821526 respectively.\n",
      "Average Precision, Recall, and F1 score are 0.7248705121447845, 0.7242453691509483, and 0.7256666666666667 respectively\n"
     ]
    }
   ],
   "source": [
    "LRPrediction = logisticRegressionModel.predict(testFeatures)\n",
    "f1 = f1_score(LRPrediction, y_test, average=None)\n",
    "recall = recall_score(LRPrediction, y_test, average=None)\n",
    "precision = precision_score(LRPrediction, y_test, average=None)\n",
    "printVal(f1, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xN4AYkgbNR_"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created Multinomial Naive Bayes model using scikit learn to train model based on tf-idf features of training set reviews and rating_group of the respective reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bE3bmh3GbNR_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naiveBayesModel = MultinomialNB()\n",
    "naiveBayesModel.fit(trainFeatures, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating F1 score, recall and precision for Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PcbFE2SUuIQO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 1 Precision, Recall, and F1 score is 0.70375, 0.7255154639175257, and 0.7144670050761421 respectively.\n",
      "For class 2 Precision, Recall, and F1 score is 0.6355, 0.6195466731659761, and 0.6274219424904356 respectively.\n",
      "For class 3 Precision, Recall, and F1 score is 0.79225, 0.7888971869554394, and 0.7905700386678309 respectively.\n",
      "Average Precision, Recall, and F1 score are 0.7108196620781362, 0.7113197746796471, and 0.7105 respectively\n"
     ]
    }
   ],
   "source": [
    "NBPrediction = naiveBayesModel.predict(testFeatures)\n",
    "f1 = f1_score(NBPrediction, y_test, average=None)\n",
    "recall = recall_score(NBPrediction, y_test, average=None)\n",
    "precision = precision_score(NBPrediction, y_test, average=None)\n",
    "printVal(f1, recall, precision)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
